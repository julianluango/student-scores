# ğŸ¤“ Student Exam Scores - PySpark ETL & EDA

Este proyecto implementa un flujo **ETL y de AnÃ¡lisis Exploratorio de Datos (EDA)** completo sobre el dataset `student_exam_scores.csv` utilizando **Apache PySpark**.

Se aplica un proceso profesional de limpieza, transformaciÃ³n y anÃ¡lisis, siguiendo las mejores prÃ¡cticas de ingenierÃ­a de datos.

---

## ğŸ“Š DescripciÃ³n del dataset

El dataset contiene informaciÃ³n sobre el rendimiento de estudiantes en exÃ¡menes, con variables relacionadas al estudio, sueÃ±o y asistencia.

**Columnas:**
| Columna | DescripciÃ³n |
|----------|--------------|
| `student_id` | Identificador Ãºnico del estudiante |
| `hours_studied` | Horas de estudio promedio por dÃ­a |
| `sleep_hours` | Promedio de horas de sueÃ±o por dÃ­a |
| `attendance_percent` | Porcentaje de asistencia a clase |
| `previous_scores` | Puntaje promedio en exÃ¡menes previos |
| `exam_score` | Puntaje obtenido en el examen actual |

---

## âš™ï¸ Requisitos

AsegÃºrate de tener instalado:

- [Python 3.8+](https://www.python.org/downloads/)
- [Apache Spark 3.0+](https://spark.apache.org/downloads.html)
- [pyspark](https://pypi.org/project/pyspark/)

InstalaciÃ³n rÃ¡pida de PySpark:

```bash
pip install pyspark
```

---

## ğŸš€ EjecuciÃ³n del script

Ejecuta el proceso ETL en tu entorno local de Spark:

```bash
spark-submit batch.py
```

> ğŸ’¡ TambiÃ©n puedes ejecutarlo directamente desde un notebook PySpark o Databricks.

---

## ğŸ” Flujo del proceso ETL

El proceso estÃ¡ dividido en tres fases principales:

### 1ï¸âƒ£ EDA Inicial
- InspecciÃ³n de esquema y tipos de datos.  
- Conteo de valores nulos y duplicados.  
- EstadÃ­sticas descriptivas bÃ¡sicas.  

### 2ï¸âƒ£ Transformaciones bÃ¡sicas
- ConversiÃ³n de tipos numÃ©ricos.  
- EliminaciÃ³n de nulos y duplicados.  
- CreaciÃ³n de nuevas columnas:
  - `performance_level`: categorÃ­a segÃºn puntaje del examen.  
  - `study_sleep_ratio`: proporciÃ³n entre horas de estudio y horas de sueÃ±o.  
  - `exam_score_normalized`: nota normalizada entre 0 y 1.  

### 3ï¸âƒ£ EDA Final
- DistribuciÃ³n por nivel de desempeÃ±o.  
- Promedios por grupos de asistencia.  
- Correlaciones entre variables numÃ©ricas.  
- EstadÃ­sticas finales tras la limpieza.  

---

## ğŸ’¾ Resultados

El dataset procesado se guarda en formato **CSV**, optimizado para anÃ¡lisis posteriores.

**Ruta de salida:**
```
data/processed_student_exam_scores.csv
```

El archivo contiene columnas limpias y enriquecidas, listas para ser analizadas o cargadas en herramientas como Power BI, Databricks o Spark SQL.

---

## ğŸ“ˆ Ejemplo de salida

| student_id | hours_studied | sleep_hours | attendance_percent | previous_scores | exam_score | performance_level | study_sleep_ratio | exam_score_normalized |
|-------------|---------------|--------------|--------------------|-----------------|-------------|--------------------|-------------------|-----------------------|
| S001 | 8.0 | 8.8 | 72.1 | 45 | 30.2 | Bajo | 0.91 | 0.12 |
| S004 | 3.5 | 4.8 | 95.1 | 66 | 34.0 | Bajo | 0.73 | 0.21 |
| S009 | 6.2 | 7.5 | 85.3 | 77 | 78.0 | Bueno | 0.83 | 0.69 |

---

## ğŸ§® TecnologÃ­as usadas

- **Apache Spark** â€“ Procesamiento distribuido
- **PySpark DataFrames** â€“ TransformaciÃ³n y anÃ¡lisis estructurado
- **Python** â€“ Script principal y automatizaciÃ³n
- **CSV** â€“ Almacenamiento optimizado de salida

---

## ğŸ“œ Licencia

Este proyecto se distribuye bajo la licencia **MIT**. Puedes usarlo y modificarlo libremente citando al autor original.

